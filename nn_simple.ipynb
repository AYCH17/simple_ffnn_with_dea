{"cells":[{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor, Lambda, Compose, Normalize\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm import tqdm "]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["# on a seulement besoin de l'exécuter une fois\n","# on va faire des appels natifs\n","if not os.path.exists(\"MNIST\"):\n","    if \"linux\" in sys.platform:\n","        os.system(\"wget www.di.ens.fr/~lelarge/MNIST.tar.gz\")\n","        os.system(\"tar -zxvf MNIST.tar.gz\")\n","        os.system(\"rm MNIST.tar.gz\")\n","    elif \"win32\" in sys.platform: \n","        os.system('pwsh -command \"Invoke-WebRequest http://www.di.ens.fr/~lelarge/MNIST.tar.gz -OutFile MNIST.tar.gz\"')\n","        os.system('pwsh -command \"tar -zxvf MNIST.tar.gz\"')\n","        os.system('pwsh -command \"rm MNIST.tar.gz\"')\n","    else:\n","        print(\"tough luck buddy!\")\n"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["# Chargement du dataset MNIST\n","# on va appliquer les opérations de conversion ici pour fins de rapidité\n","train_data = datasets.MNIST(\n","    root=\"./\", # le dossier racine où se trouve le dossier MNIST \n","    train=True, # les images d'entrainement\n","    download=False, # pas besoin de télécharger\n","    transform=Compose([\n","        ToTensor(), # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] \n","        Lambda(lambda x : torch.flatten(x))]) # on \"écrase\" l'image pour retourner un vecteur contenant les pixels\n","    )\n","\n","test_data = datasets.MNIST(\n","    root=\"./\", \n","    train=False, # les images de validation\n","    download=False,\n","    transform=Compose([\n","        ToTensor(), # https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor\n","        Lambda(lambda x : torch.flatten(x))]) # https://pytorch.org/docs/stable/generated/torch.flatten.html\n","    )\n"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["# Création des dataloader\n","# On va utiliser les dataloader pour charger les images dynamiquement et appliquer les transformations désirées.\n","# Dans notre cas, la transformation est torchvision.transforms.ToTensor()\n","# C'est la façon privilégiée de faire, en particulier lorsqu'on a de grosses bases de données qui ne peuvent pas être complètement stockées en mémoire vive.\n","# On va tricher sur le batch size pour simplifier l'entrainement : on va tout charger en mémoire (ce sont des petites images donc ça va aller)\n","train_batch_size = 60000\n","test_batch_size = 10000\n","train_dataloader = DataLoader(train_data, batch_size=train_batch_size, pin_memory=True)\n","test_dataloader = DataLoader(test_data, batch_size=test_batch_size, pin_memory=True)\n","\n","train_set = train_dataloader.dataset.data.flatten(-2)/255.\n","train_targets = train_dataloader.dataset.targets\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["class NeuralNet(nn.Module):\n","    \"\"\"Implémente un réseau de neurones linéaire très simple (perceptron multicouche),\n","       inspiré de celui de 3blue1brown.\n","\n","       trois couches pleinement connectées\n","       \n","       784 -> 16 -> 16 -> 10\n","\n","       activation sigmoide et logits obtenus à l'aide de LogSoftMax\n","\n","       les gradients sont désactivés pour permettre à l'étudiant d'entrainer\n","       le réseau à l'aide de métaheuristiques.\n","\n","    Args:\n","        nn (torch.nn.Module): hérite de cette classe, (pas obligatoire, mais ça facilite les choses)\n","    \"\"\"\n","    def __init__(self):\n","        \"\"\"Initialise le réseau de neurones\n","        \"\"\"\n","        super(NeuralNet, self).__init__()\n","        \n","        # les différentes couches\n","        self.fc1 = nn.Linear(28*28, 16)\n","        self.fc2 = nn.Linear(16, 16)\n","        self.fc3 = nn.Linear(16, 10)\n","\n","        # la fonction pour les logits (retourne le \"score\" des classes)\n","        self.logsoftmax = nn.LogSoftmax(dim=0)\n","        # la fonction pour calculer le loss (l'erreur de prédiction)\n","        self.loss_fn = nn.CrossEntropyLoss()\n","\n","    @torch.no_grad()\n","    def forward(self, x:torch.Tensor) -> torch.Tensor:\n","        \"\"\"\n","        Calcule le résultat du réseau de neurones sur une ou plusieurs images.\n","\n","        Args:\n","            x (torch.Tensor): l'image d'entrée, normalisée et écrasée, taille [B,N] où:\n","            - B est le batch size   \n","            - N le nombre de pixel\n","\n","        Returns:\n","            torch.Tensor: le résultat de taille [B,C] du traitement par le réseau où:\n","            - B est le batch size\n","            - C est le nombre de classes \n","        \"\"\"\n","        # on \"applatit\" l'image, le -2 indique que l'on joins les deux dernières dimensions, \n","        # la largeur et la longueur pour que les pixels soient dans la même dimension \n","        x = torch.sigmoid(self.fc1(x)) # activation sur la première couche\n","        x = torch.sigmoid(self.fc2(x)) # activation sur la deuxième couche\n","        x = self.fc3(x) # calcul de la dernière couche\n","        return x\n","\n","    def loss(self, x:torch.Tensor, y:torch.Tensor) -> torch.Tensor:\n","        \"\"\"Fonction pour retourner le loss de notre réseau sur un ensemble de prédictions.\n","\n","        Args:\n","            x (torch.Tensor): le tenseur avec les prédictions\n","            y (torch.Tensor): la solution\n","\n","        Returns:\n","            torch.Tensor: la perte calculée selon le cross entropy loss: https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n","        \"\"\"\n","        return self.loss_fn(x, y)\n","\n","    def get_weights_and_bias(self) -> torch.Tensor:\n","        \"\"\"Fonction utilitaire qui retourne un vecteur concaténant les poids et biais de notre réseau de neurones.\n","\n","        Returns:\n","            torch.Tensor: un vecteur de dimension 16*784+16*16+10*16+16+16+10 qui représente une concaténation aplatie\n","             des poids des couches fc1,fc2,fc3 et des biais des couches fc1,fc2,fc3\n","        \"\"\"\n","        return  torch.cat((\n","            self.fc1.weight.data.flatten(),\n","            self.fc2.weight.data.flatten(), \n","            self.fc3.weight.data.flatten(), \n","            self.fc1.bias.data.flatten(), \n","            self.fc2.bias.data.flatten(), \n","            self.fc3.bias.data.flatten()\n","            ))\n","\n","    @torch.no_grad()\n","    def set_weights_and_bias(self, x:torch.Tensor) -> None:\n","        \"\"\"Fonction utilitaire pour mettre à jour les poids et les biais du réseau de neurones\n","           à partir d'un individu issu d'un algorithme d'optimisation quelconque.\n","\n","           On va donc extraire et remettre en forme les sections respectives du vecteur et les assigner aux couches correspondantes\n","\n","        Args:\n","            x (torch.Tensor): un vecteur de dimension 16*784+16*16+10*16+16+16+10 qui représente une concaténation aplatie\n","             des poids des couches fc1,fc2,fc3 et des biais des couches fc1,fc2,fc3\n","        \"\"\"\n","        # les index des fin poids et des biais\n","        iw1,iw2,iw3,ib1,ib2,ib3 = 12544, 12800, 12960, 12976, 12992, 13002\n","        self.fc1.weight.data = x[0:iw1].reshape(16, 784)\n","        self.fc2.weight.data = x[iw1:iw2].reshape(16, 16)\n","        self.fc3.weight.data = x[iw2:iw3].reshape(10, 16)\n","        self.fc1.bias.data = x[iw3:ib1]\n","        self.fc2.bias.data = x[ib1:ib2]\n","        self.fc3.bias.data = x[ib2:ib3]\n","\n","    @torch.no_grad()\n","    def fonction_objective(self, dataloader:DataLoader) -> torch.Tensor:\n","        \"\"\"Bonne pratique pour le chargement de données -- Ne pas utiliser pour cet exercice\n","\n","        Args:\n","            dataloader (DataLoader): le dataloader qui contient les données pour évaluation/entrainement\n","\n","        Returns:\n","            torch.Tensor: le loss/le score du réseau de neurones\n","        \"\"\"\n","        loss = torch.zeros(1)\n","\n","        for batch, (X,y) in enumerate(dataloader):\n","            # on calcule l'erreur de prédiction\n","            pred = self(X)\n","            loss += self.loss(pred, y) # le loss est le résultat de la fonction objective, on cherche à le minimiser\n","\n","        # on va calculer le loss moyen\n","        #loss = loss / len(dataloader)\n","        return loss\n","    \n","    @torch.no_grad()\n","    def fast_fonction_objective(self, x:torch.tensor, targets:torch.tensor) -> torch.Tensor:\n","        \"\"\"utiliser cette fonction pour le calcul du score du réseau de neurones\n","\n","        Args:\n","            x (torch.tensor): un tenseur de taille BxN contenant les données pour évaluation/entrainement\n","            targets (torch.tensor): un vecteur de taille B contenant la classe de chaque image\n","\n","        Returns:\n","            torch.Tensor: le loss/le score du réseau de neurones\n","        \"\"\"\n","        loss = torch.zeros(1)\n","\n","        # on calcule l'erreur de prédiction\n","        pred = self(x.double())\n","        return self.loss(pred, targets) # le loss est le résultat de la fonction objective, on cherche à le minimiser\n","\n","\n","    @torch.no_grad()\n","    def run_objective_on_train(self,x):\n","        self.set_weights_and_bias(torch.from_numpy(x))\n","        return self.fast_fonction_objective(train_set,train_targets)\n","   \n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["# Fonction d'évaluation de la performance de notre réseau de neurones\n","# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n","def test(dataloader, model): \n","    size = len(dataloader.dataset)\n","    model.eval()\n","    test_loss, correct = 0, 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X.double())\n","            test_loss += model.loss_fn(pred, y).item()\n","            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","    print(\"New\\n\",correct,size)\n","    test_loss /= size\n","    correct /= size\n","    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")        \n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["# Comme le dataloader est lent et qu'on peut stocker MNIST en mémoire, on va le faire pour \n","# rendre le calcul de la fonction objective beaucoup plus rapide.\n","# Il est donc recommandé d'utiliser la fonction fast_fonction_objective pour obtenir le loss \n","\n","\n","# pour calculer le loss/fitness du réseau sur les images\n","# appelez \n","# remarquez que si vous voulez évaluer plusieurs individus en même temps que vous pourriez instancier plusieurs NeuralNet...\n","# ce n'est pas vraiment possible pour les réseaux énormes, mais dans ce cas ça devrait aller...\n"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["##### IMPLÉMENTEZ VOTRE ALGORITHME ET ROUTINE D'ENTRAINEMENT ICI\n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["\n","def train_with_dea(fobj, bounds, mut=0.8, crossp=0.7, popsize=20, its=1000):\n","    NN = NeuralNet()\n","    dimensions = len(bounds)\n","    pop = np.random.rand(popsize, dimensions)\n","    min_b, max_b = np.asarray(bounds).T\n","    diff = np.fabs(min_b - max_b)\n","    pop_denorm = min_b + pop * diff\n","    fitness = np.asarray([])\n","    \n","    for k in range(len(pop)) : \n","        fitness = np.append(fitness,fobj(NN, pop_denorm[k]))\n","\n","    best_idx = np.argmin(fitness)\n","    best = pop_denorm[best_idx]\n","    for i in tqdm(range(its)):\n","        for j in range(popsize):\n","            idxs = [idx for idx in range(popsize) if idx != j]\n","            a, b, c = pop[np.random.choice(idxs, 3, replace = False)]\n","            mutant = np.clip(a + mut * (b - c), 0, 1)\n","            cross_points = np.random.rand(dimensions) < crossp\n","            if not np.any(cross_points):\n","                cross_points[np.random.randint(0, dimensions)] = True\n","            trial = np.where(cross_points, mutant, pop[j])\n","            trial_denorm = min_b + trial * diff\n","        \n","            ##\n","            f = fobj(NN, trial_denorm)\n","            if f < fitness[j]:\n","                fitness[j] = f\n","                pop[j] = trial\n","                if f < fitness[best_idx]:\n","                    best_idx = j\n","                    best = trial_denorm\n","        \n","    return best, fitness[best_idx]\n","\n","\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["def print_results():  \n","    return"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [3:48:03<00:00, 13.68s/it]\n","[ 0.6        -1.          0.75328994 ...  0.68658722  1.\n","  1.        ] 2.1879496894113797\n","New\n"," 2292.0 10000\n","Test Error: \n"," Accuracy: 22.9%, Avg loss: 0.000216 \n","\n"]}],"source":["\n","popsize = input(\"Entrer la taille de la population\")\n","its = input(\"Entrer le nombre de generations : \")\n","\n","##Train\n","best_weights_bias , score = train_with_dea(NeuralNet.run_objective_on_train, [(-1,1)] * 13002,popsize=int(popsize),its= int(its))\n","print(best_weights_bias,score)\n","\n","#Test\n","NN =NeuralNet()\n","NN.set_weights_and_bias(torch.from_numpy(best_weights_bias))\n","test(test_dataloader,NN)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3.9.2 64-bit","metadata":{"interpreter":{"hash":"2a6ed1285f5ba108d72d5ff2c469f70bfbcd02f5c6d189e0a2739924c28b3ac1"}}}}}